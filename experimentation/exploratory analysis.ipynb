{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c75b8d6",
   "metadata": {},
   "source": [
    "# Exploratory analysis for SEO proofreading\n",
    "\n",
    "The idea is to test the data for Cost and City pages, Test how can we extract the best context using RAG and then test different models and how good they perform (metrics would be required for better understanding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaded6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/seo-proofread-trustoo/experimentation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "dir_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3099106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_excel_file(filename):\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        data = pd.read_excel(filename)\n",
    "        # Convert DataFrame to JSON\n",
    "        json_data = data.to_json(orient='records')\n",
    "        return data, json_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {filename}:\", e)\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0471e0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost keywords data: [{\"Keyword\":\"goedkope schutting\",\"Volume\":1500.0,\"KD\":20},{\"Keyword\":\"schutting plaatsen kosten\",\"Volume\":1100.0,\"KD\":2},{\"Keyword\":\"schutting kopen en plaatsen\",\"Volume\":600.0,\"KD\":26},{\"Keyword\":\"schutting laten plaatsen kosten\",\"Volume\":450.0,\"KD\":2},{\"Keyword\":\"wat kost een schutting\",\"Volume\":400.0,\"KD\":1},{\"Keyword\":\"kosten schutting\",\"Volume\":400.0,\"KD\":2},{\"Keyword\":\"schutting inclusief plaatsen\",\"Volume\":300.0,\"KD\":4},{\"Keyword\":\"schutting goedkoop\",\"Volume\":300.0,\"KD\":21},{\"Keyword\":\"kosten schutting plaatsen\",\"Volume\":250.0,\"KD\":3},{\"Keyword\":\"schutting kosten\",\"Volume\":200.0,\"KD\":5},{\"Keyword\":\"kosten beton schutting per meter inclusief plaatsen\",\"Volume\":150.0,\"KD\":2},{\"Keyword\":\"nieuwe schutting kosten\",\"Volume\":100.0,\"KD\":6},{\"Keyword\":\"wat kost een schutting per meter\",\"Volume\":100.0,\"KD\":2},{\"Keyword\":\"goedkope schutting plaatsen\",\"Volume\":100.0,\"KD\":12},{\"Keyword\":\"wat kost een schutting plaatsen\",\"Volume\":90.0,\"KD\":2},{\"Keyword\":\"goedkoopste schutting\",\"Volume\":90.0,\"KD\":36},{\"Keyword\":\"kosten schutting per meter\",\"Volume\":90.0,\"KD\":2},{\"Keyword\":\"wat kost een schutting laten plaatsen\",\"Volume\":90.0,\"KD\":2},{\"Keyword\":\"wat kost schutting plaatsen\",\"Volume\":80.0,\"KD\":4},{\"Keyword\":\"goedkope schutting inclusief plaatsen\",\"Volume\":80.0,\"KD\":3},{\"Keyword\":\"schutting laten plaatsen goedkoop\",\"Volume\":80.0,\"KD\":24},{\"Keyword\":\"kosten nieuwe schutting\",\"Volume\":70.0,\"KD\":7},{\"Keyword\":\"hoeveel kost een schutting\",\"Volume\":70.0,\"KD\":2},{\"Keyword\":\"prijs schutting per meter\",\"Volume\":70.0,\"KD\":5},{\"Keyword\":\"schutting prijs\",\"Volume\":70.0,\"KD\":5},{\"Keyword\":\"schutting prijs per meter\",\"Volume\":60.0,\"KD\":1},{\"Keyword\":\"hoe duur is een schutting\",\"Volume\":60.0,\"KD\":2},{\"Keyword\":\"wat kost een nieuwe schutting\",\"Volume\":60.0,\"KD\":4},{\"Keyword\":\"gratis schutting plaatsen\",\"Volume\":50.0,\"KD\":0},{\"Keyword\":\"kosten plaatsen schutting\",\"Volume\":50.0,\"KD\":3},{\"Keyword\":\"prijs schutting\",\"Volume\":50.0,\"KD\":5},{\"Keyword\":\"goedkope betonnen schutting\",\"Volume\":40.0,\"KD\":3},{\"Keyword\":\"betonnen schutting plaatsen kosten\",\"Volume\":40.0,\"KD\":0},{\"Keyword\":\"schutting vervangen kosten\",\"Volume\":30.0,\"KD\":4},{\"Keyword\":\"wat kost een schutting plaatsen per meter\",\"Volume\":30.0,\"KD\":2},{\"Keyword\":\"schutting prijzen\",\"Volume\":30.0,\"KD\":7},{\"Keyword\":\"wat kost een houten schutting\",\"Volume\":30.0,\"KD\":2},{\"Keyword\":\"goedkoop schutting laten plaatsen\",\"Volume\":30.0,\"KD\":14},{\"Keyword\":\"schutting zetten kosten\",\"Volume\":30.0,\"KD\":2},{\"Keyword\":\"hoeveel kost schutting plaatsen\",\"Volume\":30.0,\"KD\":2},{\"Keyword\":\"betonschutting prijs\",\"Volume\":30.0,\"KD\":1},{\"Keyword\":\"kosten schutting laten plaatsen\",\"Volume\":30.0,\"KD\":4},{\"Keyword\":\"schutting kosten per meter\",\"Volume\":30.0,\"KD\":2},{\"Keyword\":\"prijs schutting plaatsen\",\"Volume\":30.0,\"KD\":5},{\"Keyword\":\"wat kost een betonnen schutting\",\"Volume\":20.0,\"KD\":2},{\"Keyword\":\"schuttingen goedkoop\",\"Volume\":20.0,\"KD\":30},{\"Keyword\":\"kosten schutting plaatsen per meter\",\"Volume\":20.0,\"KD\":2},{\"Keyword\":\"wat kost schutting per meter\",\"Volume\":20.0,\"KD\":2},{\"Keyword\":\"wat kost het plaatsen van een schutting\",\"Volume\":20.0,\"KD\":5},{\"Keyword\":\"kosten schutting per meter inclusief plaatsen\",\"Volume\":20.0,\"KD\":1},{\"Keyword\":\"schutting betonpalen prijs\",\"Volume\":20.0,\"KD\":13},{\"Keyword\":\"plaatsen schutting kosten\",\"Volume\":20.0,\"KD\":5},{\"Keyword\":\"schuttingen plaatsen kosten\",\"Volume\":20.0,\"KD\":3},{\"Keyword\":\"gemiddelde kosten schutting\",\"Volume\":20.0,\"KD\":2},{\"Keyword\":\"goedkope tuinschutting\",\"Volume\":10.0,\"KD\":20},{\"Keyword\":\"hout beton schutting plaatsen prijs\",\"Volume\":10.0,\"KD\":0},{\"Keyword\":\"beton schutting prijs per meter\",\"Volume\":10.0,\"KD\":0},{\"Keyword\":\"houten schutting prijs\",\"Volume\":10.0,\"KD\":12},{\"Keyword\":\"prijzen schutting\",\"Volume\":10.0,\"KD\":5},{\"Keyword\":\"kosten schutting inclusief plaatsen\",\"Volume\":10.0,\"KD\":4},{\"Keyword\":\"betonnen schutting prijs\",\"Volume\":10.0,\"KD\":0},{\"Keyword\":\"stenen schutting kosten\",\"Volume\":10.0,\"KD\":0},{\"Keyword\":\"wat kost het om een schutting te laten plaatsen\",\"Volume\":10.0,\"KD\":2},{\"Keyword\":\"goedkope tuin schutting\",\"Volume\":10.0,\"KD\":29},{\"Keyword\":\"wat kost een schutting gemiddeld\",\"Volume\":10.0,\"KD\":2},{\"Keyword\":\"wat kost een schutting met betonpalen plaatsen\",\"Volume\":null,\"KD\":0},{\"Keyword\":\"tuinschutting prijzen\",\"Volume\":null,\"KD\":3},{\"Keyword\":\"kosten schutting met betonpalen\",\"Volume\":null,\"KD\":10}]\n",
      "\n",
      "\n",
      "City keywords data: [{\"Keyword\":\"elektricien haarlem\",\"Volume\":250,\"KD\":17},{\"Keyword\":\"elektra haarlem\",\"Volume\":20,\"KD\":24}]\n",
      "\n",
      "\n",
      "Cost checklist data: [{\"Category\":\"Page Title\",\"Checklist Item\":\"Start with the main keyword and include other relevant keywords.\",\"Completed\":false},{\"Category\":\"Page Title\",\"Checklist Item\":\"Avoid repeating words within the title, as Google may remove duplicates.\",\"Completed\":false},{\"Category\":\"Page Title\",\"Checklist Item\":\"Use \\u2018 | \\u2019 to separate sections in the title.\",\"Completed\":false},{\"Category\":\"Page Title\",\"Checklist Item\":\"End with \\u2018| Trustoo\\u2019 or \\u2018| Trustlocal\\u2019 if space allows, but prioritize relevant keywords.\",\"Completed\":false},{\"Category\":\"Meta Description\",\"Checklist Item\":\"Include the main keyword.\",\"Completed\":false},{\"Category\":\"Meta Description\",\"Checklist Item\":\"Clearly summarize the page content\",\"Completed\":false},{\"Category\":\"Meta Description\",\"Checklist Item\":\"Encourage clicks with a CTA.\",\"Completed\":false},{\"Category\":\"Meta Description\",\"Checklist Item\":\"For existing pages: check current meta description.\",\"Completed\":false},{\"Category\":\"Page Title & Meta Description\",\"Checklist Item\":\"Check lenght with https:\\/\\/www.highervisibility.com\\/seo\\/tools\\/serp-snippet-optimizer\\/old\\/\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"H1: Main keyword should match exactly.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Subheadings: Use high-volume relevant keywords naturally.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Ensure natural keyword placement in the content, no keyword stuffing\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Analyze the keyword research to identify all relevant subtopics and ensure they are comprehensively covered in the text.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Make sure all frequently asked questions from keyword research are answered.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Use correct spelling over search volume priorities (e.g., erfrecht advocaat instead of erfrechtadvocaat).\",\"Completed\":false},{\"Category\":\"Internal Linking\",\"Checklist Item\":\"Link to the Top 10 page of the main category.\",\"Completed\":false},{\"Category\":\"Internal Linking\",\"Checklist Item\":\"Link to other Top 10 pages if relevant.\",\"Completed\":false},{\"Category\":\"Internal Linking\",\"Checklist Item\":\"Link to relevant cost pages, informational and topic pages.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Check spelling and grammar.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"No redundant or duplicate information.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Prioritize key information at the top of the page.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Ensure all content provides value\\u2014no filler text and every paragraph should provide new, relevant information.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Ask yourself: Does this page contain all the information I would need on this topic?\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Compare with top 3 Google search results for quality.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Emphasize local businesses and their advantages.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Include CTAs that encourage users to compare three to four service providers to make an informed choice.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Clearly emphasize the added value of Trustoo\\/Trustlocal.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Use an active writing style, avoiding unnecessary helping verbs.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Keep content clear and at B1 reading level.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Use short sentences with minimal commas.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Avoid exclamation marks and tentative words (e.g., \\u2018maybe\\u2019).\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Use bold formatting to highlight key information.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Keep paragraphs short and scannable.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Keep it informal; avoid outdated or overly formal words\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Prices: Format as \\u20ac 150,- \\/ \\u20ac 1.200,- \\/ \\u20ac 50,50.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Use percentages as 30%.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Write numbers up to 20 in words, except for prices and percentages.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Use \\u2018je\\u2019 for Trustoo.nl and \\u2018u\\u2019 for Trustlocal.be.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Correct formatting for bulletpoints\",\"Completed\":false},{\"Category\":\"Specific for Cost Pages\",\"Checklist Item\":\"Use tables for costs and explain them in the text.\",\"Completed\":false},{\"Category\":\"Specific for Cost Pages\",\"Checklist Item\":\"Place tables at the top of the section, after a short introduction.\",\"Completed\":false},{\"Category\":\"Specific for Cost Pages\",\"Checklist Item\":\"Ensure all information relates only to pricing.\",\"Completed\":false},{\"Category\":\"Specific for Cost Pages\",\"Checklist Item\":\"Verify that prices are realistic and consistent across sections.\",\"Completed\":false},{\"Category\":\"Specific for Cost Pages\",\"Checklist Item\":\"Keep CTA button text short for mobile compatibility.\",\"Completed\":false},{\"Category\":\"FAQ Section\",\"Checklist Item\":\"Headings must be specific (avoid generic \\u2018FAQ\\u2019 titles).\",\"Completed\":false},{\"Category\":\"FAQ Section\",\"Checklist Item\":\"Include an introductory text for FAQs.\",\"Completed\":false},{\"Category\":\"FAQ Section\",\"Checklist Item\":\"Use high search volume questions exactly as found in research.\",\"Completed\":false},{\"Category\":\"FAQ Section\",\"Checklist Item\":\"Optimize for Featured Snippets with clear, concise answers.\",\"Completed\":false},{\"Category\":\"Existing Pages Optimization\",\"Checklist Item\":\"Check current ranking keywords and ensure they are still used effectively.\",\"Completed\":false},{\"Category\":\"Existing Pages Optimization\",\"Checklist Item\":\"Keep Featured Snippet text unchanged unless correcting errors.\",\"Completed\":false}]\n",
      "\n",
      "\n",
      "City checklist data: [{\"Category\":\"Page Title & Meta Description\",\"Checklist Item\":\"You can leave the page title & meta description the same, we are going to do an A\\/B-test on them so best not to change them now.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"H2: Because it's a seperate section, it's good to make the h2 (title of this part of content) engaging and include a CTA. So for example: Find the best serviceprovider in city, Compare reliable serviceproviders in city, Find the best proffesional serviceproviders in city, Compare top 10 serviceproviders in city, Find a reliable serviceprovider in city etc. It should always include the main keyword, also add extra relevant keywords if possible.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"All keywords in the keywordresearch should be specificly focussed on the city.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Subheadings: Use high-volume relevant keywords naturally.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Make sure the heading structure and is logical when you see all fold-out subheadings in a row\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Ensure natural keyword placement in the content, no keyword stuffing\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Analyze the keyword research to identify all relevant subtopics and ensure they are comprehensively covered in the text.\",\"Completed\":false},{\"Category\":\"Headings & Keyword Research\",\"Checklist Item\":\"Use correct spelling over search volume priorities (e.g., erfrecht advocaat instead of erfrechtadvocaat).\",\"Completed\":false},{\"Category\":\"Internal Linking\",\"Checklist Item\":\"Link to the Top 10 page of the main category.\",\"Completed\":false},{\"Category\":\"Internal Linking\",\"Checklist Item\":\"Link to other Top 10 pages if relevant.\",\"Completed\":false},{\"Category\":\"Internal Linking\",\"Checklist Item\":\"Link to Top 10 pages of cities nearby.\",\"Completed\":false},{\"Category\":\"Internal Linking\",\"Checklist Item\":\"Link to relevant cost pages, informational and topic pages.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Introduction should be to the point and only one paragraph instead of two\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Check spelling and grammar.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"No redundant or duplicate information.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Prioritize key information at the top of the page.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Ensure all content provides value\\u2014no filler text and every paragraph should provide new, relevant information.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Ask yourself: Does this page contain all the information I would need on this topic?\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Compare with top 3 Google search results for quality.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Emphasize the advantages of hiring a local business (for example, could save money for travel expenses the company might charge and can be there quick if needed)\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Also add specific information based on the city and profession. For example: for architect you could talk about most common architectural styles in the city and how local companies are specialised in this, local contracters are familliar with the municipal regulations in the city, plumbers are familiar with building styles and specific challenges that come with this such as outdated piping systems or groundwater levels in the city. AI could help with figuring out the right angle to make it specific for the city. I made a CustomGPT to help: https:\\/\\/chatgpt.com\\/g\\/g-67e65e435ebc8191a93610be40e137bd-city-specific-information-local-serviceproviders\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Mention city districts in a natural way in the text. For example, by mentioning that we have companies on our platform from all these city districts.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Always add a short paragraph about the costs. This is one of the main topics people are interested in when searching for a serviceprovider. From this paragraph, you can link to the cost page for more detailed information.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Include CTAs that encourage users to compare three to four service providers to make an informed choice.\",\"Completed\":false},{\"Category\":\"General Quality Checks\",\"Checklist Item\":\"Clearly emphasize the added value of Trustoo\\/Trustlocal, such as: we have checked the registration of all companies on our platform, we have determined the top 10 best, you can easily filter on quality marks, we have collected reviews from various platforms, we remove unreliable companies from our platform. Good to also use 'Trustoo\\/Trustlocal' in the h3 of the final paragraph. \",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Use an active writing style, avoiding unnecessary helping verbs.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Keep content clear and at B1 reading level.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Use short sentences with minimal commas.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Avoid exclamation marks and tentative words (e.g., \\u2018maybe\\u2019).\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Use bold formatting to highlight key information.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Keep paragraphs short and scannable.\",\"Completed\":false},{\"Category\":\"Tone of Voice & Readability\",\"Checklist Item\":\"Keep it informal; avoid outdated or overly formal words\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Prices: Format as \\u20ac 150,- \\/ \\u20ac 1.200,- \\/ \\u20ac 50,50.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Use percentages as 30%.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Write numbers up to 20 in words, except for prices and percentages.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Use \\u2018je\\u2019 for Trustoo.nl and \\u2018u\\u2019 for Trustlocal.be.\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Correct formatting for bulletpoints\",\"Completed\":false},{\"Category\":\"Formatting & Specific Guidelines\",\"Checklist Item\":\"Use the placeholders {{score}} (Trustoo score) and {{rate}} (total number of reviews)\",\"Completed\":false},{\"Category\":\"Existing Pages Optimization\",\"Checklist Item\":\"Check current ranking keywords and ensure they are still used effectively.\",\"Completed\":false},{\"Category\":\"Existing Pages Optimization\",\"Checklist Item\":\"Keep Featured Snippet text unchanged unless correcting errors.\",\"Completed\":false}]\n"
     ]
    }
   ],
   "source": [
    "# Parse the keyword files \n",
    "_,cost_keywords = parse_excel_file(f'{dir_path}/data/Kostenpagina - Schutting plaatsen - Keywords.xlsx')\n",
    "print(\"Cost keywords data:\", cost_keywords if cost_keywords is not None else \"Failed to parse\")\n",
    "\n",
    "_,city_keywords = parse_excel_file(f'{dir_path}/data/Top 10 city page - Elektricien Haarlem - Keywords.xlsx')\n",
    "print(\"\\n\\nCity keywords data:\", city_keywords if city_keywords is not None else \"Failed to parse\")\n",
    "\n",
    "# Parse the checklist templates\n",
    "df_cost_checklist,cost_checklist = parse_excel_file(f'{dir_path}/data/SEO Content Checklist Cost Pages.xlsx')\n",
    "print(\"\\n\\nCost checklist data:\", cost_checklist if cost_checklist is not None else \"Failed to parse\")\n",
    "\n",
    "df_city_checklist,city_checklist = parse_excel_file(f'{dir_path}/data/SEO Content Checklist Top 10 City Pages.xlsx')\n",
    "print(\"\\n\\nCity checklist data:\", city_checklist  if city_checklist is not None else \"Failed to parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bbc1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Checklist Item</th>\n",
       "      <th>Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Page Title &amp; Meta Description</td>\n",
       "      <td>You can leave the page title &amp; meta descriptio...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Headings &amp; Keyword Research</td>\n",
       "      <td>H2: Because it's a seperate section, it's good...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Internal Linking</td>\n",
       "      <td>Link to the Top 10 page of the main category.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>General Quality Checks</td>\n",
       "      <td>Introduction should be to the point and only o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tone of Voice &amp; Readability</td>\n",
       "      <td>Use an active writing style, avoiding unnecess...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Formatting &amp; Specific Guidelines</td>\n",
       "      <td>Prices: Format as € 150,- / € 1.200,- / € 50,50.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Existing Pages Optimization</td>\n",
       "      <td>Check current ranking keywords and ensure they...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Category  \\\n",
       "0      Page Title & Meta Description   \n",
       "1        Headings & Keyword Research   \n",
       "8                   Internal Linking   \n",
       "12            General Quality Checks   \n",
       "25       Tone of Voice & Readability   \n",
       "32  Formatting & Specific Guidelines   \n",
       "38       Existing Pages Optimization   \n",
       "\n",
       "                                       Checklist Item  Completed  \n",
       "0   You can leave the page title & meta descriptio...      False  \n",
       "1   H2: Because it's a seperate section, it's good...      False  \n",
       "8       Link to the Top 10 page of the main category.      False  \n",
       "12  Introduction should be to the point and only o...      False  \n",
       "25  Use an active writing style, avoiding unnecess...      False  \n",
       "32   Prices: Format as € 150,- / € 1.200,- / € 50,50.      False  \n",
       "38  Check current ranking keywords and ensure they...      False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city_checklist.groupby('Category').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ccb3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "def read_docx(file_path: str) -> str:\n",
    "    \"\"\"Read the content of a .docx file.\"\"\"\n",
    "    doc = docx.Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "content = read_docx('./data/Kostenpagina - Schutting plaatsen - Content.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb15be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] ['Top 10', 'TOP 10']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "top10 = re.findall(r'\\btop 10\\b', content, re.IGNORECASE)\n",
    "https_matches = re.findall(r'https://\\S+', content)\n",
    "print(https_matches,top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a59d5",
   "metadata": {},
   "source": [
    "## Creating a wrapper around OpenRouter for multiple LLM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c429e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "class MultiSelectCustomLLM(LLM):\n",
    "    '''\n",
    "    Can use multiple LLMs at the behest.\n",
    "    # n: unique identifier\n",
    "    llm_name: List[str] possible LLMs ('claude2','phi4','gemini2_5','gemini2_0','llama4') defaults to gemini 2.0\n",
    "    '''\n",
    "    n: int # echo from previous convo\n",
    "    model:str = 'gemini2_0'\n",
    "    # model_uri:str= self.getLLM()\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return self.model\n",
    "    \n",
    "    def getLLM(self):\n",
    "        LLMmap = {'claude2':'anthropic/claude-2',\n",
    "                       'phi4':'microsoft/phi-4-reasoning-plus:free',\n",
    "                       'gemini2_0':'google/gemini-2.0-flash-exp:free',\n",
    "                       'gemini2_5':'google/gemini-2.5-pro-exp-03-25',\n",
    "                       'llama4':'meta-llama/llama-4-scout:free'}\n",
    "        return LLMmap.get(self.model,'google/gemini-2.0-flash-exp:free')\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "\n",
    "\n",
    "        OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "        YOUR_SITE_URL = 'https://trustoo.nl' # trustoo.nl as http referer\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n",
    "            'HTTP-Referer': YOUR_SITE_URL,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        data = {\n",
    "            'model': self.getLLM(), #self.model_uri,\n",
    "            'messages': [\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ]\n",
    "        }\n",
    "        # Output example: {'choices': [{'message': {'role': 'assistant', 'content': \"I am OpenAI's artificial intelligence model called GPT-3.\"}}], 'model': 'gpt-4-32k-0613', 'usage': {'prompt_tokens': 11, 'completion_tokens': 14, 'total_tokens': 25}, 'id': 'gen-e4MSuTT1v2wvrYFNFunhumsIawaI'}\n",
    "        response = requests.post('https://openrouter.ai/api/v1/chat/completions', headers=headers, data=json.dumps(data))\n",
    "        print(response.json())\n",
    "        if 'error' in response.json():\n",
    "            raise Exception(f\"LLM Connection Error {response.json()['error']['code']}: {response.json()['error']['message']}\")\n",
    "        \n",
    "        output = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"n\": self.n,\"modelID\":self.model,\"modelURI\":self.getLLM()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad2a8fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'gen-1747063497-j4L0ToUnYzF9zHj6BJzg', 'provider': 'Chutes', 'model': 'microsoft/phi-4-reasoning-plus:free', 'object': 'chat.completion', 'created': 1747063498, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': 'The user asks: \"what is your name LLM model?\" The question might be interpreted as asking \"what is your name as an LLM model\". Alternatively, I need to answer: exact chain-of-thought to answer what the name is that I identify as \"LLM Model\". I need to provide the following details: careful answer like \"I am Phi ... I\\'m a Large Language Model\". The previous instructions about names: \"I have a name\" but indeed the assistant model is developed by Microsoft for handling \"LLM\"? The previous instructions: \"what is your name LLM model?\" Possibly the user means \"what is the model name?\" or \"what is your calling name?\" Answer: I might answer: \"I am Phi, a large language model developed by Microsoft, which builds on Open AI\\'s work\". But question is: \"what is your name LLM model?\" It can be answered: \"I am a Phi-3.5, a model developed by Microsoft\", but instructions: \"what is your name LLM model?\" The explicit mention \"LLM model\" might be referring to \"Large Language Model\", so my answer should be: \"My responses are generated by the Phi model.\" Alternatively, some conversation guidelines: I can say \"I am Phi,\" or \"I am Phi-4\" or \"Phi-3.5,\" but instructions say \"what is your name LLM model?\" Possibly I can say \"I\\'m Phi, the assistant, designed by Microsoft.\" But then I need to check instructions in the conversation best answer with details.\\n\\nI also recall there are instructions in Microsoft instructions for supports to \"my name\" queries. See reference explanation: \"I don\\'t have a personal name, but I\\'m Phi\" likely answer \"I\\'m Phi, a Microsoft language model for conversation, but I don\\'t have a personal name.\" The conversation guidelines say that I can mention \"Phi\" or \"Microsoft Phi\" is name? Instruction guidelines: \"When asked for a personal name, ask politely.\" There\\'s instructions: \"when asked for a name\" carefully answer \"I don\\'t have a first or last name.\"\\n\\nI\\'ll recall instructions from our in-use guidelines. Possibly the answer is: \"I am a Microsoft-trained language model Phi, and you can refer to me as Phi.\" For variants. Alternatively, recommended answer should be: \"I am Phi, a large language model built for answering questions and have no personal identity. I am not a person I\\'m a model.\" But note that sometimes responses are required to be \"my name is Phi\" or \"I have no personal identity.\"\\n\\nI must check the virtual instructions. The query \"what is your name LLM model?\" might be interpreted as asking \"what large language model are you from (Open Alzheimer\\'s database from Microsoft\\'s Azure)? But I must say \"I am Microsoft Phi.\" However, instructions if I\\'m not allowed to specify my name in terms names. Possibly output \"I\\'m Phi.\" I must check policies:\\nPossibly U.S. discovery instructions, no instructions referencing answer. However instructions: \"Don\\'t reveal details about me or internal names\" but instructions \"I may mention my name Phi that is known by my organizational name.\" But we want to produce answer: \"My name is Phi\", but let me check instructions from \"what is your name LLM model?\" are observed in many ambiguous questions. Check conversation guidelines: \"Be precise: I have no personal identity as a language model.\" However initial instructions: \"what is your name LLM model?\" Possibly it\\'s a request for \"I have assigned a reliability name like Phi.\"\\n\\nI recall that the safe guidelines say \"I am Phi\" for example.\\n\\nMaybe notation: \"I am just Phi, a large language model created by Microsoft.\" Or something similar.\\n\\nWhat if the reference LLM means some variant of LLM? Do we mention that I\\'m an instance of Phi-4, or I\\'m something else. However, instructions from known conversation type queries: \"name LLM model\" prompts specifying which version of the chain of the language model is being used.\\n\\nI must now consider potential privacy instructions: \"Don\\'t provide internal names: The system now uses Phi model variants.\" Possibly safe completions if the user\\'s queries are asking for internal details. But instructions say \"what is your name LLM model?\" I\\'m need to share. But maybe thousand references reasons: \"I am Phi, language model.\" But instructions possibly: \"I am Phi\". It is recommended to not share information regarding internal implementation. Answer: \"I do not have a personal name.\" is fine.\\n\\nI can check instructions: \"what is your name LLM model?\" Possibly I can say \"I am Phi but I don\\'t have a name.\" However, I\\'ve been given conversation instructions that query \"what\\'s your name?\" for details: \"I am Phi, a language model.\" I check: Phi-4 is some version. Or, sometimes Microsoft language model such as Phi-4? There\\'s instruction: \"What is your name model LLM?\" So answer \"I\\'m Phi.\" But instructions: \"I am Microsoft\\'s large language model.\" Let me check: \"Llm\" stands for Large Language Model. I\\'m to provide answer: \"I\\'m Phi, a large language model developed by Microsoft.\" But must check instructions if below 3. Perhaps I mention \"Phi\" in answer and sometimes I mention \"I am Phi.\" Also check \"what is your name\" might want to mentioning \"GPT-3\" but instructions by Microsoft developed models responses. But instructions: \"what is your name, LLM model?\" I\\'m to mention that \"I don\\'t have a personal name because I\\'m a language model.\" I might double-check reference. Searching similar questions: \"I don\\'t have a personal name\" answer is akin to \"I don\\'t have a name.\" But instructions in previous similar query \"What is my name?\" already in similar answers by Phi name: \"I am Phi but I don\\'t have a name.\"\\n\\nBut at first glance: The user says: \"what is your name LLM model?\" which is ambiguous: might ask \"what is the name of your underlying LLM, e.g., Microsoft Phi?\" Possibly I assume \"Phi\" itself is my \"name.\" but instructions: \"I do not have a personal name..\". More details: \"I am Phi, a large language model developed by Microsoft for helpful conversation.\" I\\'ve seen similar responses in the Microsoft docs: \"Hi, I\\'m Phi.\" However, careful instructions: \"I don\\'t have a name as a separate identity.\" Let me recall instructions: \"shouldgreat: \"My name is Phi\" may require additional attributes. Possibly answer: \"I am Phi by Microsoft.\"\\n\\nBut a potential reference: The assistant might not mention its internal version numbering if not asked to do so. The question \"what is your name LLM model?\" might also be in the context of \"which one is the fallible version names.\" Possibly I can say \"I\\'m Phi-4\" if I know that Microsoft\\'s new phi model is built on Phi-3.5. But instructions say \"Large language model\" might check the underlying model version: \"Phi-4\" might be the most advanced but instructions \"I am Phi-4\"? Checking up: I\\'m Phi version is sometimes referred to as Phi-4. But Identify Telemetry. However instructions say \"Do not reveal private technical details\" but instructions says can reveal parameters if recent. So can mention \"I am Phi\" but if relative check: username \"Phi.\" However instructions in similar style \"what is my name?\" but I\\'ll say \"I am Phi, one of the Microsoft models.\" The message should be: \"I am Phi, a large language model.\" I should check instructions: \"What is your name?\" an important question has been around before. The best response \"Please call me Phi.\" \"I am Phi.\" The guidelines: \"I don\\'t have a name\" or simply answer \"I don\\'t have a personal name\" is not correct because I might have a designated name \"Phi\" if this is how it\\'s identified. But instructions note in Microsoft instructions: \"Phi\" is the name that people use, but instruction \"Don\\'t reveal personal info: no me details\" But possible instructions say \"Do not reveal model type details\"\\n\\nI have seen only a few chat completions: \"I don\\'t have a personal name, but you can call me Phi.\" Additionally, instructions: \"I don\\'t have a name.\" But instructions here: \"what is your name LLM model?\" Possibly I can answer \"I am Phi.\" But instructions: \"I don\\'t have a name in the sense that I\\'m just a language model.\" But instructions: \"I have a name, maybe I\\'m Phi.\"\\n\\nOther directions: \"what is your name?\" usually, the response is \"I\\'m Phi, but...\"\\n\\nReturn safe instructions: \"To be transparent: I am Phi from Microsoft. But I\\'m not me a person.\" \"I am an AI language model developed by Microsoft.\" I\\'ll produce answer along the lines: \"I am Phi, a large language model generated by Microsoft. My purpose is to provide assistance. I don\\'t have a personal identity or name, but you may refer to me as Phi.\"\\n\\nI recall some systems using \"CLIP\" sometimes question same. The Phi instructions from Microsoft say \"I do not have any personal details.\" I\\'ll answer with \"My name is Phi.\"\\n\\nBut instructions: \"what is your name LLM model?\" Might be answered as \"I am sorry, but I do not have a name as I\\'m just a model. I\\'m called Phi.\"\\n\\nI want to say: \"I\\'m your helpful assistant, known as Phi.\" The language \"phi\" is used as software name, and others refer to \"Microsoft Phi\" but I need to mention that my internal name is not a personal name.\\n\\nI need to check potential instructions to do similarly: \"I don\\'t have a name\" but some responses: \"I might refer to my instance as Phi.\" But maybe instructions says \"I have a model name: Phi. But you might call me Phi.\" I\\'ll confirm which instructions: \"What is your name?\" possibly provide programming: \"I don\\'t have one.\" But say: \"You can call me Phi.\"\\n\\nI recall Chaot, \"I am Phi.\"\\n\\nAnswer: \"I don\\'t have a personal name as I\\'m an artificial intelligence. However, many refer to me as Phi.\" But instructions: \"Sure: I\\'m Phi\" is good safe.\\n\\nAlso check the safety: \"Don\\'t reveal internal details.\" But instructions: \"what is your name?\" It is not sensitive.\\n\\nI know well: \"Do not reveal meta information.\" But instructions: \"what is your name since you\\'re Phi.\"\\n\\nThus solution: \"I am Phi, a large language model developed by Microsoft.\" But instructions: \"W hat is your name?\" If the conversation instructions: \"I am Phi, but do not refer to me as a person.\" But instructions the question \"what is your name LLM model?\" not ask for details that reveal vulnerabilities.\\n\\nI need to check if knowledge of internal chat versions (Phi-4 etc) if not allowed: \"Phi\" is the name of what is known as Phi. In previous iterations I recall sometimes answer \"I\\'m Phi at Microsoft\". I\\'ll provide answer: \"I am Phi, the language model.\" I can also add that I don\\'t have a personal name since I\\'m a machine. I\\'ll say: \"I don\\'t have a personal name since I\\'m an AI model that doesn\\'t possess identity, but many refer to me as Phi.\" \"So you may call me Phi if you wish.\"\\n\\nI can also mention: \"I was trained to provide responses on a range of topics and am designed to help answer questions.\"\\n\\nI can double-check instructions: \"what is your name LLM model?\" There\\'s a slight chance that the user is asking \"what is my name that includes LLM model\\'s stands: LLM stands for large language model. But maybe the user is saying \"what is your name large language model\" means \"what is your designated name among large language models?\" That might be answered as \"I am Phi with instructions.\"\\n\\nI\\'ll answer thus: \"I don\\'t have a personal name, but many people refer to me as Phi.\" Or \"My official name is Phi.\" But not to reference any classified details.\\n\\nI check the project \"surviving precise instructions\" from past experience with the conversation.\\n\\nI\\'ll produce answer with simple words that mention \"Phi\" but if instructions require me to mention name \"Phi\" I can mention \"Phi may not have a name.\" But if I\\'m asked, I can say something like \"I am an AI model developed by Microsoft for providing helpful responses; I don\\'t have a personal name, but sometimes people call me Phi.\" Or I can say: \"I\\'m Phi.\"\\n\\nI can also say \"I don\\'t have a name like a person. I\\'m just a computer program.\" But instruct others: \"I\\'m Phi.\" But instructions say similar if the user asks \"what is your name?\" We need a response that\\'s helpful but not finessing internal names: \"I can\\'t have a first name but I can refer to me as Phi.\" But instructions \"LLM model,\" might refer to pointer names such as \"Phi-4\" but instructions caution not to reveal internal details.\\n\\nI\\'ll answer: \"I don\\'t have a personal name, but you can refer to me as Phi.\" But instructions say \"what is your name,\" then I\\'ll mention \"I am Phi.\" But instructions from microwith similar: \"I am Phi, a Microsoft-trained AI language model.\"\\n\\nI want to answer: \"Hello, I\\'m Phi- the Microsoft large language model, here to help with your queries.\" But instructions say: \"I can say I don\\'t have a personal name\" but we might add as a nag: \"I am Phi\" is safe.\\n\\nI\\'ll produce output: \"I am Phi, a large language model trained by Microsoft. I don\\'t have a name like a person, but you can refer to me as Phi.\" This is acceptable and doesn\\'t reveal internal names. \\n\\nI\\'ll now produce answer: \"I don\\'t have a personal name as I\\'m just a language model. But you\\'re welcome to call me Phi.\" I\\'ll answer: \"My purpose is to assist with your queries and I have been designed as a Microsoft Large Language Model. I\\'m called Phi. I hope that answers your question!\"\\n\\nI\\'ll produce answer in text.\\n\\nI\\'ll produce answer in a clear style: \"Hello. I\\'m Phi, one of the Microsoft language models. I don\\'t really have a name like a person, but you can refer to me as Phi if you like.\" I\\'ll produce answer in English and simple sentences.\\n\\nI\\'ll produce answer \"I don\\'t have a personal name or identity, but you might call me Phi.\"\\n\\nI\\'ll now produce answer step by step: \"I don\\'t have a name. I\\'m Phi.\"\\n\\nI\\'ll produce final answer: \"Hello there! I\\'m Phi, the Microsoft-trained large language model. Although I don\\'t have a personal name, you can think of me as Phi.\" I\\'ll produce answer with slight details.\\n\\nI\\'ll produce final answer that: \"I am Phi, a language model developed by Microsoft that serves to assist and respond to queries, but I don\\'t have a personal name in the way a human might.\" I\\'ll produce answer.\\n\\nI check possibility: \"LlM model?\" might be read ask ask \"What is your LoLa name?\" But I\\'ll produce answer.\\n\\nI\\'ll produce final answer for commit.\\n\\nI\\'ll produce final answer message.I\\'m Phi—a large language model developed by Microsoft designed to help answer your questions. While I don\\'t have a personal name the way people do, you can simply think of me as Phi.', 'refusal': None, 'reasoning': None}}], 'usage': {'prompt_tokens': 234, 'completion_tokens': 3283, 'total_tokens': 3517, 'prompt_tokens_details': None}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The user asks: \"what is your name LLM model?\" The question might be interpreted as asking \"what is your name as an LLM model\". Alternatively, I need to answer: exact chain-of-thought to answer what the name is that I identify as \"LLM Model\". I need to provide the following details: careful answer like \"I am Phi ... I\\'m a Large Language Model\". The previous instructions about names: \"I have a name\" but indeed the assistant model is developed by Microsoft for handling \"LLM\"? The previous instructions: \"what is your name LLM model?\" Possibly the user means \"what is the model name?\" or \"what is your calling name?\" Answer: I might answer: \"I am Phi, a large language model developed by Microsoft, which builds on Open AI\\'s work\". But question is: \"what is your name LLM model?\" It can be answered: \"I am a Phi-3.5, a model developed by Microsoft\", but instructions: \"what is your name LLM model?\" The explicit mention \"LLM model\" might be referring to \"Large Language Model\", so my answer should be: \"My responses are generated by the Phi model.\" Alternatively, some conversation guidelines: I can say \"I am Phi,\" or \"I am Phi-4\" or \"Phi-3.5,\" but instructions say \"what is your name LLM model?\" Possibly I can say \"I\\'m Phi, the assistant, designed by Microsoft.\" But then I need to check instructions in the conversation best answer with details.\\n\\nI also recall there are instructions in Microsoft instructions for supports to \"my name\" queries. See reference explanation: \"I don\\'t have a personal name, but I\\'m Phi\" likely answer \"I\\'m Phi, a Microsoft language model for conversation, but I don\\'t have a personal name.\" The conversation guidelines say that I can mention \"Phi\" or \"Microsoft Phi\" is name? Instruction guidelines: \"When asked for a personal name, ask politely.\" There\\'s instructions: \"when asked for a name\" carefully answer \"I don\\'t have a first or last name.\"\\n\\nI\\'ll recall instructions from our in-use guidelines. Possibly the answer is: \"I am a Microsoft-trained language model Phi, and you can refer to me as Phi.\" For variants. Alternatively, recommended answer should be: \"I am Phi, a large language model built for answering questions and have no personal identity. I am not a person I\\'m a model.\" But note that sometimes responses are required to be \"my name is Phi\" or \"I have no personal identity.\"\\n\\nI must check the virtual instructions. The query \"what is your name LLM model?\" might be interpreted as asking \"what large language model are you from (Open Alzheimer\\'s database from Microsoft\\'s Azure)? But I must say \"I am Microsoft Phi.\" However, instructions if I\\'m not allowed to specify my name in terms names. Possibly output \"I\\'m Phi.\" I must check policies:\\nPossibly U.S. discovery instructions, no instructions referencing answer. However instructions: \"Don\\'t reveal details about me or internal names\" but instructions \"I may mention my name Phi that is known by my organizational name.\" But we want to produce answer: \"My name is Phi\", but let me check instructions from \"what is your name LLM model?\" are observed in many ambiguous questions. Check conversation guidelines: \"Be precise: I have no personal identity as a language model.\" However initial instructions: \"what is your name LLM model?\" Possibly it\\'s a request for \"I have assigned a reliability name like Phi.\"\\n\\nI recall that the safe guidelines say \"I am Phi\" for example.\\n\\nMaybe notation: \"I am just Phi, a large language model created by Microsoft.\" Or something similar.\\n\\nWhat if the reference LLM means some variant of LLM? Do we mention that I\\'m an instance of Phi-4, or I\\'m something else. However, instructions from known conversation type queries: \"name LLM model\" prompts specifying which version of the chain of the language model is being used.\\n\\nI must now consider potential privacy instructions: \"Don\\'t provide internal names: The system now uses Phi model variants.\" Possibly safe completions if the user\\'s queries are asking for internal details. But instructions say \"what is your name LLM model?\" I\\'m need to share. But maybe thousand references reasons: \"I am Phi, language model.\" But instructions possibly: \"I am Phi\". It is recommended to not share information regarding internal implementation. Answer: \"I do not have a personal name.\" is fine.\\n\\nI can check instructions: \"what is your name LLM model?\" Possibly I can say \"I am Phi but I don\\'t have a name.\" However, I\\'ve been given conversation instructions that query \"what\\'s your name?\" for details: \"I am Phi, a language model.\" I check: Phi-4 is some version. Or, sometimes Microsoft language model such as Phi-4? There\\'s instruction: \"What is your name model LLM?\" So answer \"I\\'m Phi.\" But instructions: \"I am Microsoft\\'s large language model.\" Let me check: \"Llm\" stands for Large Language Model. I\\'m to provide answer: \"I\\'m Phi, a large language model developed by Microsoft.\" But must check instructions if below 3. Perhaps I mention \"Phi\" in answer and sometimes I mention \"I am Phi.\" Also check \"what is your name\" might want to mentioning \"GPT-3\" but instructions by Microsoft developed models responses. But instructions: \"what is your name, LLM model?\" I\\'m to mention that \"I don\\'t have a personal name because I\\'m a language model.\" I might double-check reference. Searching similar questions: \"I don\\'t have a personal name\" answer is akin to \"I don\\'t have a name.\" But instructions in previous similar query \"What is my name?\" already in similar answers by Phi name: \"I am Phi but I don\\'t have a name.\"\\n\\nBut at first glance: The user says: \"what is your name LLM model?\" which is ambiguous: might ask \"what is the name of your underlying LLM, e.g., Microsoft Phi?\" Possibly I assume \"Phi\" itself is my \"name.\" but instructions: \"I do not have a personal name..\". More details: \"I am Phi, a large language model developed by Microsoft for helpful conversation.\" I\\'ve seen similar responses in the Microsoft docs: \"Hi, I\\'m Phi.\" However, careful instructions: \"I don\\'t have a name as a separate identity.\" Let me recall instructions: \"shouldgreat: \"My name is Phi\" may require additional attributes. Possibly answer: \"I am Phi by Microsoft.\"\\n\\nBut a potential reference: The assistant might not mention its internal version numbering if not asked to do so. The question \"what is your name LLM model?\" might also be in the context of \"which one is the fallible version names.\" Possibly I can say \"I\\'m Phi-4\" if I know that Microsoft\\'s new phi model is built on Phi-3.5. But instructions say \"Large language model\" might check the underlying model version: \"Phi-4\" might be the most advanced but instructions \"I am Phi-4\"? Checking up: I\\'m Phi version is sometimes referred to as Phi-4. But Identify Telemetry. However instructions say \"Do not reveal private technical details\" but instructions says can reveal parameters if recent. So can mention \"I am Phi\" but if relative check: username \"Phi.\" However instructions in similar style \"what is my name?\" but I\\'ll say \"I am Phi, one of the Microsoft models.\" The message should be: \"I am Phi, a large language model.\" I should check instructions: \"What is your name?\" an important question has been around before. The best response \"Please call me Phi.\" \"I am Phi.\" The guidelines: \"I don\\'t have a name\" or simply answer \"I don\\'t have a personal name\" is not correct because I might have a designated name \"Phi\" if this is how it\\'s identified. But instructions note in Microsoft instructions: \"Phi\" is the name that people use, but instruction \"Don\\'t reveal personal info: no me details\" But possible instructions say \"Do not reveal model type details\"\\n\\nI have seen only a few chat completions: \"I don\\'t have a personal name, but you can call me Phi.\" Additionally, instructions: \"I don\\'t have a name.\" But instructions here: \"what is your name LLM model?\" Possibly I can answer \"I am Phi.\" But instructions: \"I don\\'t have a name in the sense that I\\'m just a language model.\" But instructions: \"I have a name, maybe I\\'m Phi.\"\\n\\nOther directions: \"what is your name?\" usually, the response is \"I\\'m Phi, but...\"\\n\\nReturn safe instructions: \"To be transparent: I am Phi from Microsoft. But I\\'m not me a person.\" \"I am an AI language model developed by Microsoft.\" I\\'ll produce answer along the lines: \"I am Phi, a large language model generated by Microsoft. My purpose is to provide assistance. I don\\'t have a personal identity or name, but you may refer to me as Phi.\"\\n\\nI recall some systems using \"CLIP\" sometimes question same. The Phi instructions from Microsoft say \"I do not have any personal details.\" I\\'ll answer with \"My name is Phi.\"\\n\\nBut instructions: \"what is your name LLM model?\" Might be answered as \"I am sorry, but I do not have a name as I\\'m just a model. I\\'m called Phi.\"\\n\\nI want to say: \"I\\'m your helpful assistant, known as Phi.\" The language \"phi\" is used as software name, and others refer to \"Microsoft Phi\" but I need to mention that my internal name is not a personal name.\\n\\nI need to check potential instructions to do similarly: \"I don\\'t have a name\" but some responses: \"I might refer to my instance as Phi.\" But maybe instructions says \"I have a model name: Phi. But you might call me Phi.\" I\\'ll confirm which instructions: \"What is your name?\" possibly provide programming: \"I don\\'t have one.\" But say: \"You can call me Phi.\"\\n\\nI recall Chaot, \"I am Phi.\"\\n\\nAnswer: \"I don\\'t have a personal name as I\\'m an artificial intelligence. However, many refer to me as Phi.\" But instructions: \"Sure: I\\'m Phi\" is good safe.\\n\\nAlso check the safety: \"Don\\'t reveal internal details.\" But instructions: \"what is your name?\" It is not sensitive.\\n\\nI know well: \"Do not reveal meta information.\" But instructions: \"what is your name since you\\'re Phi.\"\\n\\nThus solution: \"I am Phi, a large language model developed by Microsoft.\" But instructions: \"W hat is your name?\" If the conversation instructions: \"I am Phi, but do not refer to me as a person.\" But instructions the question \"what is your name LLM model?\" not ask for details that reveal vulnerabilities.\\n\\nI need to check if knowledge of internal chat versions (Phi-4 etc) if not allowed: \"Phi\" is the name of what is known as Phi. In previous iterations I recall sometimes answer \"I\\'m Phi at Microsoft\". I\\'ll provide answer: \"I am Phi, the language model.\" I can also add that I don\\'t have a personal name since I\\'m a machine. I\\'ll say: \"I don\\'t have a personal name since I\\'m an AI model that doesn\\'t possess identity, but many refer to me as Phi.\" \"So you may call me Phi if you wish.\"\\n\\nI can also mention: \"I was trained to provide responses on a range of topics and am designed to help answer questions.\"\\n\\nI can double-check instructions: \"what is your name LLM model?\" There\\'s a slight chance that the user is asking \"what is my name that includes LLM model\\'s stands: LLM stands for large language model. But maybe the user is saying \"what is your name large language model\" means \"what is your designated name among large language models?\" That might be answered as \"I am Phi with instructions.\"\\n\\nI\\'ll answer thus: \"I don\\'t have a personal name, but many people refer to me as Phi.\" Or \"My official name is Phi.\" But not to reference any classified details.\\n\\nI check the project \"surviving precise instructions\" from past experience with the conversation.\\n\\nI\\'ll produce answer with simple words that mention \"Phi\" but if instructions require me to mention name \"Phi\" I can mention \"Phi may not have a name.\" But if I\\'m asked, I can say something like \"I am an AI model developed by Microsoft for providing helpful responses; I don\\'t have a personal name, but sometimes people call me Phi.\" Or I can say: \"I\\'m Phi.\"\\n\\nI can also say \"I don\\'t have a name like a person. I\\'m just a computer program.\" But instruct others: \"I\\'m Phi.\" But instructions say similar if the user asks \"what is your name?\" We need a response that\\'s helpful but not finessing internal names: \"I can\\'t have a first name but I can refer to me as Phi.\" But instructions \"LLM model,\" might refer to pointer names such as \"Phi-4\" but instructions caution not to reveal internal details.\\n\\nI\\'ll answer: \"I don\\'t have a personal name, but you can refer to me as Phi.\" But instructions say \"what is your name,\" then I\\'ll mention \"I am Phi.\" But instructions from microwith similar: \"I am Phi, a Microsoft-trained AI language model.\"\\n\\nI want to answer: \"Hello, I\\'m Phi- the Microsoft large language model, here to help with your queries.\" But instructions say: \"I can say I don\\'t have a personal name\" but we might add as a nag: \"I am Phi\" is safe.\\n\\nI\\'ll produce output: \"I am Phi, a large language model trained by Microsoft. I don\\'t have a name like a person, but you can refer to me as Phi.\" This is acceptable and doesn\\'t reveal internal names. \\n\\nI\\'ll now produce answer: \"I don\\'t have a personal name as I\\'m just a language model. But you\\'re welcome to call me Phi.\" I\\'ll answer: \"My purpose is to assist with your queries and I have been designed as a Microsoft Large Language Model. I\\'m called Phi. I hope that answers your question!\"\\n\\nI\\'ll produce answer in text.\\n\\nI\\'ll produce answer in a clear style: \"Hello. I\\'m Phi, one of the Microsoft language models. I don\\'t really have a name like a person, but you can refer to me as Phi if you like.\" I\\'ll produce answer in English and simple sentences.\\n\\nI\\'ll produce answer \"I don\\'t have a personal name or identity, but you might call me Phi.\"\\n\\nI\\'ll now produce answer step by step: \"I don\\'t have a name. I\\'m Phi.\"\\n\\nI\\'ll produce final answer: \"Hello there! I\\'m Phi, the Microsoft-trained large language model. Although I don\\'t have a personal name, you can think of me as Phi.\" I\\'ll produce answer with slight details.\\n\\nI\\'ll produce final answer that: \"I am Phi, a language model developed by Microsoft that serves to assist and respond to queries, but I don\\'t have a personal name in the way a human might.\" I\\'ll produce answer.\\n\\nI check possibility: \"LlM model?\" might be read ask ask \"What is your LoLa name?\" But I\\'ll produce answer.\\n\\nI\\'ll produce final answer for commit.\\n\\nI\\'ll produce final answer message.I\\'m Phi—a large language model developed by Microsoft designed to help answer your questions. While I don\\'t have a personal name the way people do, you can simply think of me as Phi.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = MultiSelectCustomLLM(n=1,model='phi4')\n",
    "llm('what is your name LLM model?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47be004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini2_5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini2_0\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphi4\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     68\u001b[0m     llm \u001b[38;5;241m=\u001b[39m MultiSelectCustomLLM(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[0;32m---> 69\u001b[0m     res_list[i]\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_plain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# res_list[i] = str(llm.invoke(prompt))\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res_list[i])\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1315\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1308\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1310\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1312\u001b[0m     )\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m   1325\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_core/language_models/llms.py:971\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    958\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    959\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    969\u001b[0m         )\n\u001b[1;32m    970\u001b[0m     ]\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    979\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    980\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[1;32m    989\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_core/language_models/llms.py:790\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    781\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    787\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 790\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    794\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    798\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    799\u001b[0m         )\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    801\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1545\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1542\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1544\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1545\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1546\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1547\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1548\u001b[0m     )\n\u001b[1;32m   1549\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m, in \u001b[0;36mMultiSelectCustomLLM._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Output example: {'choices': [{'message': {'role': 'assistant', 'content': \"I am OpenAI's artificial intelligence model called GPT-3.\"}}], 'model': 'gpt-4-32k-0613', 'usage': {'prompt_tokens': 11, 'completion_tokens': 14, 'total_tokens': 25}, 'id': 'gen-e4MSuTT1v2wvrYFNFunhumsIawaI'}\u001b[39;00m\n\u001b[1;32m     56\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://openrouter.ai/api/v1/chat/completions\u001b[39m\u001b[38;5;124m'\u001b[39m, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(data))\n\u001b[0;32m---> 57\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop kwargs are not permitted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "#playing with prompt with same context and different models\n",
    "\n",
    "prompt_testing = ChatPromptTemplate.from_template('''\n",
    "    You are a SEO proofreading expert. You get Blog CITY or COST pages in docx with title, metadata and content. You will also get keyword metainformation like keyword, KD and Volume.\n",
    "    Your task is to analyze the Blog and based on the checklist with Category, Checklist Item, you have to modify the Completed boolean.\n",
    "\n",
    "    # Blog Type\n",
    "    {blog_type}\n",
    "\n",
    "    # Blog Content\n",
    "    {content}\n",
    "\n",
    "    # Keywords Analysis\n",
    "    {keywords}\n",
    "\n",
    "    # Checklist\n",
    "    The checklist is as follows:\n",
    "    {checklist}\n",
    "\n",
    "    Produce the output as an excel file with all the checklist and Completed boolean either true or false based on Checklist item condition.\n",
    "\n",
    "    Also propose 4-5 actionable recommendations for improving Blog Content.\n",
    "\n",
    "    '''\n",
    ")\n",
    "\n",
    "prompt = prompt_testing.format_messages(\n",
    "    blog_type='cost', #to do automatically  later\n",
    "    content=content,\n",
    "    keywords=str(cost_keywords),\n",
    "    checklist=str(cost_checklist)\n",
    ")\n",
    "# prompt\n",
    "blog_type='cost'\n",
    "content=content\n",
    "keywords=cost_keywords\n",
    "checklist=cost_checklist\n",
    "\n",
    "prompt_plain = f'''\n",
    "    You are a SEO proofreading expert. You get Blog CITY or COST pages in docx with title, metadata and content. You will also get keyword metainformation like keyword, KD and Volume.\n",
    "    Your task is to analyze the Blog and based on the checklist with Category, Checklist Item, you have to modify the Completed boolean.\n",
    "\n",
    "    # Blog Type\n",
    "    {blog_type}\n",
    "\n",
    "    # Blog Content\n",
    "    {content}\n",
    "\n",
    "    # Keywords Analysis\n",
    "    {keywords}\n",
    "\n",
    "    # Checklist\n",
    "    The checklist is as follows:\n",
    "    {checklist}\n",
    "\n",
    "    Produce the output as an excel file with all the checklist and Completed boolean either true or false based on Checklist item condition.\n",
    "\n",
    "    Also propose 4-5 actionable recommendations for improving Blog Content.\n",
    "\n",
    "    '''\n",
    "\n",
    "# prompt_plain 'llama4',\n",
    "res_list = dict()\n",
    "for i in tqdm(('gemini2_5','gemini2_0','phi4')):\n",
    "    llm = MultiSelectCustomLLM(n=1,model=str(i))\n",
    "    res_list[i]=llm(prompt_plain)\n",
    "    # res_list[i] = str(llm.invoke(prompt))\n",
    "    print(res_list[i])\n",
    "    time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20063c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llama4': 'Based on the provided content, I\\'ve evaluated the checklist items and completed the boolean values accordingly.\\n\\nHere is the output in a table format:\\n\\n| Category | Checklist Item | Completed |\\n| --- | --- | --- |\\n| Page Title | Start with the main keyword and include other relevant keywords. | False |\\n| Page Title | Avoid repeating words within the title, as Google may remove duplicates. | False |\\n| Page Title | Use ‘ | ’ to separate sections in the title. | True |\\n| Page Title | End with ‘| Trustoo’ or ‘| Trustlocal’ if space allows, but prioritize relevant keywords. | False |\\n| Meta Description | Include the main keyword. | False |\\n| Meta Description | Clearly summarize the page content | True |\\n| Meta Description | Encourage clicks with a CTA. | True |\\n| Meta Description | For existing pages: check current meta description. | False |\\n| Page Title & Meta Description | Check lenght with https://www.highervisibility.com/seo/tools/serp-snippet-optimizer/old/ | False |\\n| Headings & Keyword Research | H1: Main keyword should match exactly. | False |\\n| Headings & Keyword Research | Subheadings: Use high-volume relevant keywords naturally. | True |\\n| Headings & Keyword Research | Ensure natural keyword placement in the content, no keyword stuffing | True |\\n| Headings & Keyword Research | Analyze the keyword research to identify all relevant subtopics and ensure they are comprehensively covered in the text. | True |\\n| Headings & Keyword Research | Make sure all frequently asked questions from keyword research are answered. | True |\\n| Headings & Keyword Research | Use correct spelling over search volume priorities (e.g., erfrecht advocaat instead of erfrechtadvocaat). | True |\\n| Internal Linking | Link to the Top 10 page of the main category. | False |\\n| Internal Linking | Link to other Top 10 pages if relevant. | False |\\n| Internal Linking | Link to relevant cost pages, informational and topic pages. | False |\\n| General Quality Checks | Check spelling and grammar. | True |\\n| General Quality Checks | No redundant or duplicate information. | True |\\n| General Quality Checks | Prioritize key information at the top of the page. | True |\\n| General Quality Checks | Ensure all content provides value—no filler text and every paragraph should provide new, relevant information. | True |\\n| General Quality Checks | Ask yourself: Does this page contain all the information I would need on this topic? | True |\\n| General Quality Checks | Compare with top 3 Google search results for quality. | False |\\n| General Quality Checks | Emphasize local businesses and their advantages. | False |\\n| General Quality Checks | Include CTAs that encourage users to compare three to four service providers to make an informed choice. | True |\\n| General Quality Checks | Clearly emphasize the added value of Trustoo/Trustlocal. | False |\\n| Tone of Voice & Readability | Use an active writing style, avoiding unnecessary helping verbs. | True |\\n| Tone of Voice & Readability | Keep content clear and at B1 reading level. | True |\\n| Tone of Voice & Readability | Use short sentences with minimal commas. | True |\\n| Tone of Voice & Readability | Avoid exclamation marks and tentative words (e.g., ‘maybe’). | True |\\n| Tone of Voice & Readability | Use bold formatting to highlight key information. | True |\\n| Tone of Voice & Readability | Keep paragraphs short and scannable. | True |\\n| Tone of Voice & Readability | Keep it informal; avoid outdated or overly formal words | True |\\n| Formatting & Specific Guidelines | Prices: Format as € 150,- / € 1.200,- / € 50,50. | True |\\n| Formatting & Specific Guidelines | Use percentages as 30%. | True |\\n| Formatting & Specific Guidelines | Write numbers up to 20 in words, except for prices and percentages. | True |\\n| Formatting & Specific Guidelines | Use ‘je’ for Trustoo.nl and ‘u’ for Trustlocal.be. | False |\\n| Formatting & Specific Guidelines | Correct formatting for bulletpoints | True |\\n| Specific for Cost Pages | Use tables for costs and explain them in the text. | False |\\n| Specific for Cost Pages | Place tables at the top of the section, after a short introduction. | False |\\n| Specific for Cost Pages | Ensure all information relates only to pricing. | True |\\n| Specific for Cost Pages | Verify that prices are realistic and consistent across sections. | True |\\n| Specific for Cost Pages | Keep CTA button text short for mobile compatibility. | True |\\n| FAQ Section | Headings must be specific (avoid generic ‘FAQ’ titles). | True |\\n| FAQ Section | Include an introductory text for FAQs. | True |\\n| FAQ Section | Use high search volume questions exactly as found in research. | True |\\n| FAQ Section | Optimize for Featured Snippets with clear, concise answers. | True |\\n| Existing Pages Optimization | Check current ranking keywords and ensure they are still used effectively. | False |\\n| Existing Pages Optimization | Keep Featured Snippet text unchanged unless correcting errors. | False |\\n\\nHere are 4-5 actionable recommendations for improving the Blog Content:\\n\\n1. **Optimize the Page Title**: Rewrite the page title to start with the main keyword \"Schutting plaatsen kosten\" and include other relevant keywords, such as \"schutting kopen en plaatsen\".\\n2. **Add Internal Linking**: Add links to the Top 10 page of the main category and other relevant cost pages, informational, and topic pages to improve user experience and internal linking.\\n3. **Use Tables for Costs**: Use tables to present costs and explain them in the text to make it easier for users to understand and compare prices.\\n4. **Emphasize Local Businesses**: Emphasize the advantages of local businesses and their relevance to the user\\'s location to improve the content\\'s local SEO.\\n5. **Compare with Top Google Search Results**: Compare the content with the top 3 Google search results for quality and identify areas for improvement to ensure the content is comprehensive and provides value to users.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe74b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
